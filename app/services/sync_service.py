"""
åŒæ­¥æœåŠ¡æ¨¡å—

æä¾›æ•°æ®åŒæ­¥çš„æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
1. äº¤æ˜“æ‰€ä¿¡æ¯åŒæ­¥
2. è‚¡ç¥¨æ¸…å•åŒæ­¥
3. è‚¡ç¥¨è¡Œæƒ…æ•°æ®åŒæ­¥
"""

from typing import Dict, List, Any, Optional
import json
import os
import logging
from datetime import datetime, date
import time

logger = logging.getLogger(__name__)


class SyncService:
    """åŒæ­¥æœåŠ¡ç±»"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è·å–API tokenï¼Œç¡®ä¿å®‰å…¨æ€§
        self.token = os.getenv('STOCK_API_TOKEN')
        if not self.token:
            raise ValueError("STOCK_API_TOKEN not found in environment variables. Please check your .env file.")
    
    def sync_exchanges_info(self, 
                          force_update: bool = False,
                          target_file: str = 'exchange_code.json') -> Dict[str, Any]:
        """
        åŒæ­¥äº¤æ˜“æ‰€ä¿¡æ¯åˆ°æœ¬åœ°æ–‡ä»¶
        
        Args:
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
            target_file: ç›®æ ‡æ–‡ä»¶å
            
        Returns:
            Dict: åŒæ­¥ç»“æœ
        """
        try:
            # è¿™é‡Œæ¨¡æ‹Ÿä»è¿œç¨‹APIè·å–äº¤æ˜“æ‰€ä¿¡æ¯
            # å®é™…é¡¹ç›®ä¸­ï¼Œè¿™åº”è¯¥æ˜¯çœŸæ­£çš„APIè°ƒç”¨
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯å¦éœ€è¦æ›´æ–°
            if os.path.exists(target_file) and not force_update:
                file_stats = os.stat(target_file)
                file_age_hours = (time.time() - file_stats.st_mtime) / 3600
                
                if file_age_hours < 24:  # æ–‡ä»¶ä¸è¶…è¿‡24å°æ—¶ï¼Œè·³è¿‡æ›´æ–°
                    return {
                        'success': True,
                        'action': 'skipped',
                        'message': 'äº¤æ˜“æ‰€ä¿¡æ¯æ–‡ä»¶è¾ƒæ–°ï¼Œè·³è¿‡æ›´æ–°',
                        'file_path': target_file,
                        'file_age_hours': round(file_age_hours, 2)
                    }
            
            # è¯»å–ç°æœ‰æ–‡ä»¶ä½œä¸ºæ¨¡æ‹Ÿçš„"è¿œç¨‹API"æ•°æ®
            if os.path.exists(target_file):
                with open(target_file, 'r', encoding='utf-8') as f:
                    exchanges_data = json.load(f)
                
                # æ›´æ–°æ—¶é—´æˆ³
                for exchange in exchanges_data:
                    exchange['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # ä¿å­˜æ›´æ–°åçš„æ•°æ®
                with open(target_file, 'w', encoding='utf-8') as f:
                    json.dump(exchanges_data, f, ensure_ascii=False, indent=2)
                
                return {
                    'success': True,
                    'action': 'updated',
                    'message': 'äº¤æ˜“æ‰€ä¿¡æ¯åŒæ­¥æˆåŠŸ',
                    'file_path': target_file,
                    'exchanges_count': len(exchanges_data),
                    'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
            else:
                return {
                    'success': False,
                    'action': 'failed',
                    'error': f'äº¤æ˜“æ‰€ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {target_file}',
                    'message': 'è¯·ç¡®ä¿exchange_code.jsonæ–‡ä»¶å­˜åœ¨'
                }
                
        except Exception as e:
            logger.error(f"åŒæ­¥äº¤æ˜“æ‰€ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'success': False,
                'action': 'failed',
                'error': str(e),
                'message': 'äº¤æ˜“æ‰€ä¿¡æ¯åŒæ­¥å¤±è´¥'
            }
    
    def sync_stock_lists(self,
                        exchange_codes: Optional[List[str]] = None,
                        force_update: bool = False,
                        output_dir: str = 'constants/stock_lists') -> Dict[str, Any]:
        """
        åŒæ­¥è‚¡ç¥¨æ¸…å•åˆ°æœ¬åœ°JSONæ–‡ä»¶
        
        Args:
            exchange_codes: è¦åŒæ­¥çš„äº¤æ˜“æ‰€ä»£ç åˆ—è¡¨
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            Dict: åŒæ­¥ç»“æœ
        """
        try:
            if exchange_codes is None:
                exchange_codes = ['XSHG', 'XSHE', 'BJSE']
            
            from data_fetcher.exchange_stocks import fetch_all_chinese_exchange_stocks
            
            # æ‰§è¡ŒåŒæ­¥
            sync_results = fetch_all_chinese_exchange_stocks(
                token=self.token,
                output_dir=output_dir
            )
            
            # ç»Ÿè®¡ç»“æœ
            total_stocks = 0
            successful_exchanges = 0
            failed_exchanges = []
            
            for result in sync_results:
                if result['success']:
                    successful_exchanges += 1
                    total_stocks += result['total_stocks']
                else:
                    failed_exchanges.append({
                        'exchange_code': result['exchange_code'],
                        'error': result['error']
                    })
            
            success = len(failed_exchanges) == 0
            
            return {
                'success': success,
                'action': 'completed',
                'message': f'è‚¡ç¥¨æ¸…å•åŒæ­¥å®Œæˆï¼ŒæˆåŠŸ: {successful_exchanges}ï¼Œå¤±è´¥: {len(failed_exchanges)}',
                'total_exchanges': len(sync_results),
                'successful_exchanges': successful_exchanges,
                'failed_exchanges': failed_exchanges,
                'total_stocks': total_stocks,
                'output_dir': output_dir,
                'sync_results': sync_results
            }
            
        except Exception as e:
            logger.error(f"åŒæ­¥è‚¡ç¥¨æ¸…å•å¤±è´¥: {e}")
            return {
                'success': False,
                'action': 'failed',
                'error': str(e),
                'message': 'è‚¡ç¥¨æ¸…å•åŒæ­¥å¤±è´¥'
            }
    
    def sync_stock_prices(self,
                         symbols: Optional[List[str]] = None,
                         start_year: int = 2000,
                         batch_size: int = 10,
                         force_update: bool = False,
                         max_stocks: int = 100,
                         stop_flag = None,
                         progress_callback = None) -> Dict[str, Any]:
        """
        åŒæ­¥è‚¡ç¥¨è¡Œæƒ…æ•°æ®åˆ°TimescaleDB
        
        Args:
            symbols: æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºç©ºåˆ™è‡ªåŠ¨è·å–
            start_year: å¼€å§‹å¹´ä»½
            batch_size: æ‰¹å¤„ç†å¤§å°
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
            max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡é™åˆ¶
            
        Returns:
            Dict: åŒæ­¥ç»“æœ
        """
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨ï¼Œä»æœ¬åœ°JSONæ–‡ä»¶è·å–
            if not symbols:
                symbols = self._get_all_stock_symbols(limit=max_stocks)
            
            if not symbols:
                return {
                    'success': False,
                    'action': 'failed',
                    'error': 'æ²¡æœ‰æ‰¾åˆ°éœ€è¦åŒæ­¥çš„è‚¡ç¥¨ä»£ç ',
                    'message': 'è¯·å…ˆåŒæ­¥è‚¡ç¥¨æ¸…å•æˆ–æŒ‡å®šè‚¡ç¥¨ä»£ç '
                }
            
            # é™åˆ¶è‚¡ç¥¨æ•°é‡
            if len(symbols) > max_stocks:
                symbols = symbols[:max_stocks]
                logger.info(f"é™åˆ¶åŒæ­¥è‚¡ç¥¨æ•°é‡ä¸º: {max_stocks}")
            
            from data_fetcher.stock_api import StockDataFetcher
            from utils.data_integration import integrate_stock_data
            
            fetcher = StockDataFetcher(self.token)
            
            # åŒæ­¥ç»Ÿè®¡
            successful_stocks = 0
            failed_stocks = []
            total_records = 0
            
            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(symbols), batch_size):
                batch_symbols = symbols[i:i + batch_size]
                
                batch_num = i//batch_size + 1
                total_batches = (len(symbols)-1)//batch_size + 1
                logger.info(f"\n{'='*70}")
                logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches}: {len(batch_symbols)}åªè‚¡ç¥¨")
                logger.info(f"æ‰¹æ¬¡èŒƒå›´: ç¬¬{i+1}-{min(i+len(batch_symbols), len(symbols))}åª / æ€»è®¡{len(symbols)}åª")
                logger.info(f"{'='*70}")
                
                for idx, symbol in enumerate(batch_symbols, 1):
                    # æ£€æŸ¥åœæ­¢æ ‡å¿—
                    if stop_flag and stop_flag.is_set():
                        logger.warning(f"\nâš ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä»»åŠ¡ä¸­æ–­äºç¬¬{i + idx}åªè‚¡ç¥¨")
                        break
                    
                    stock_num = i + idx
                    
                    # æ›´æ–°è¿›åº¦
                    if progress_callback:
                        progress_callback(stock_num, len(symbols), f"æ­£åœ¨å¤„ç†: {symbol}")
                    
                    try:
                        logger.info(f"\n[{stock_num}/{len(symbols)}] ğŸ”„ æ­£åœ¨å¤„ç†: {symbol}")
                        
                        # è·å–æ•°æ®
                        start_date = f"{start_year}-01-01"
                        logger.info(f"[{stock_num}/{len(symbols)}] ğŸ“¡ è·å–æ•°æ®: {symbol} (ä»{start_date}å¼€å§‹)")
                        records = fetcher.fetch_by_symbol(symbol, start_date=start_date)
                        
                        if records:
                            logger.info(f"[{stock_num}/{len(symbols)}] ğŸ“¥ æ¥æ”¶æ•°æ®: {symbol} - {len(records)}æ¡è®°å½•")
                            
                            # é›†æˆåˆ°æ•°æ®åº“ï¼ˆå¼€å¯æ–­ç‚¹ç»­ä¼ ï¼‰
                            logger.info(f"[{stock_num}/{len(symbols)}] ğŸ’¾ å†™å…¥æ•°æ®åº“: {symbol}")
                            result = integrate_stock_data(
                                symbol=symbol,
                                api_records=records,
                                force_update=force_update,
                                skip_existing=True  # å¯ç”¨æ–­ç‚¹ç»­ä¼ 
                            )
                            
                            if result['success']:
                                successful_stocks += 1
                                inserted = result.get('inserted_count', 0)
                                skipped = result.get('skipped_count', 0)
                                total_records += inserted
                                
                                if skipped > 0:
                                    logger.info(f"[{stock_num}/{len(symbols)}] â­ï¸  {symbol} - å·²è·³è¿‡(å·²æœ‰{skipped}æ¡è®°å½•) - {result.get('stock_name', symbol)}")
                                else:
                                    logger.info(f"[{stock_num}/{len(symbols)}] âœ… {symbol} - æˆåŠŸæ’å…¥{inserted}æ¡ - {result.get('stock_name', symbol)}")
                            else:
                                failed_stocks.append({
                                    'symbol': symbol,
                                    'error': result.get('error', 'Unknown error')
                                })
                                logger.error(f"[{stock_num}/{len(symbols)}] âŒ {symbol} - å¤±è´¥: {result.get('error')}")
                        else:
                            failed_stocks.append({
                                'symbol': symbol,
                                'error': 'No data received from API'
                            })
                            logger.warning(f"[{stock_num}/{len(symbols)}] âš ï¸  {symbol} - æ— æ•°æ®è¿”å›")
                            
                    except Exception as e:
                        failed_stocks.append({
                            'symbol': symbol,
                            'error': str(e)
                        })
                        logger.error(f"[{stock_num}/{len(symbols)}] âŒ {symbol} - å¼‚å¸¸: {e}")
                
                # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                if stop_flag and stop_flag.is_set():
                    break
                
                # æ‰¹æ¬¡å®Œæˆç»Ÿè®¡
                logger.info(f"\n{'â”€'*70}")
                logger.info(f"æ‰¹æ¬¡ {batch_num}/{total_batches} å®Œæˆ - æˆåŠŸ: {successful_stocks}åª, å¤±è´¥: {len(failed_stocks)}åª")
                logger.info(f"{'â”€'*70}\n")
                
                # æ‰¹æ¬¡é—´æš‚åœ
                if i + batch_size < len(symbols):
                    time.sleep(1)  # é¿å…APIé™æµ
            
            success_rate = successful_stocks / len(symbols) if symbols else 0
            
            return {
                'success': success_rate > 0.5,  # æˆåŠŸç‡è¶…è¿‡50%è®¤ä¸ºæˆåŠŸ
                'action': 'completed',
                'message': f'è‚¡ç¥¨è¡Œæƒ…åŒæ­¥å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.1%}',
                'total_symbols': len(symbols),
                'successful_stocks': successful_stocks,
                'failed_stocks_count': len(failed_stocks),
                'failed_stocks': failed_stocks[:10],  # åªè¿”å›å‰10ä¸ªå¤±è´¥çš„
                'total_records': total_records,
                'start_year': start_year,
                'batch_size': batch_size,
                'success_rate': success_rate
            }
            
        except Exception as e:
            logger.error(f"åŒæ­¥è‚¡ç¥¨è¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
            return {
                'success': False,
                'action': 'failed',
                'error': str(e),
                'message': 'è‚¡ç¥¨è¡Œæƒ…æ•°æ®åŒæ­¥å¤±è´¥'
            }
    
    def sync_single_stock(self,
                         symbol: str,
                         start_date: Optional[str] = None,
                         end_date: Optional[str] = None,
                         force_update: bool = False) -> Dict[str, Any]:
        """
        åŒæ­¥å•åªè‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
            
        Returns:
            Dict: åŒæ­¥ç»“æœ
        """
        try:
            from data_fetcher.stock_api import StockDataFetcher
            from utils.data_integration import integrate_stock_data
            
            fetcher = StockDataFetcher(self.token)
            
            # è·å–æ•°æ®
            records = fetcher.fetch_by_symbol(symbol, start_date, end_date)
            
            if not records:
                return {
                    'success': False,
                    'action': 'failed',
                    'error': 'APIæœªè¿”å›æ•°æ®',
                    'message': f'è‚¡ç¥¨{symbol}æ²¡æœ‰è·å–åˆ°æ•°æ®'
                }
            
            # é›†æˆåˆ°æ•°æ®åº“ï¼ˆå¼€å¯æ–­ç‚¹ç»­ä¼ ï¼‰
            result = integrate_stock_data(
                symbol=symbol,
                api_records=records,
                force_update=force_update,
                skip_existing=False  # å•ä¸ªè‚¡ç¥¨åŒæ­¥ä¸è·³è¿‡
            )
            
            if result['success']:
                return {
                    'success': True,
                    'action': 'completed',
                    'message': f'è‚¡ç¥¨{symbol}è¡Œæƒ…æ•°æ®åŒæ­¥æˆåŠŸ',
                    'symbol': symbol,
                    'records_count': len(records),
                    'inserted_count': result.get('inserted_count', 0),
                    'updated_count': result.get('updated_count', 0),
                    'date_range': {
                        'start': records[-1].date if records else None,
                        'end': records[0].date if records else None
                    }
                }
            else:
                return {
                    'success': False,
                    'action': 'failed',
                    'error': result.get('error', 'Database integration failed'),
                    'message': f'è‚¡ç¥¨{symbol}æ•°æ®åº“é›†æˆå¤±è´¥'
                }
                
        except Exception as e:
            logger.error(f"åŒæ­¥å•åªè‚¡ç¥¨å¤±è´¥ {symbol}: {e}")
            return {
                'success': False,
                'action': 'failed',
                'error': str(e),
                'message': f'è‚¡ç¥¨{symbol}åŒæ­¥å¤±è´¥'
            }
    
    def full_sync(self,
                 include_exchanges: bool = True,
                 include_stock_lists: bool = True,
                 include_stock_prices: bool = False,
                 max_stocks: int = 50,
                 start_year: int = 2020) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´åŒæ­¥
        
        Args:
            include_exchanges: æ˜¯å¦åŒ…å«äº¤æ˜“æ‰€ä¿¡æ¯åŒæ­¥
            include_stock_lists: æ˜¯å¦åŒ…å«è‚¡ç¥¨æ¸…å•åŒæ­¥
            include_stock_prices: æ˜¯å¦åŒ…å«è‚¡ç¥¨è¡Œæƒ…åŒæ­¥
            max_stocks: è¡Œæƒ…åŒæ­¥çš„æœ€å¤§è‚¡ç¥¨æ•°
            start_year: è¡Œæƒ…åŒæ­¥çš„èµ·å§‹å¹´ä»½
            
        Returns:
            Dict: åŒæ­¥ç»“æœ
        """
        try:
            results: Dict[str, Optional[Dict[str, Any]]] = {
                'exchanges': None,
                'stock_lists': None,
                'stock_prices': None
            }
            
            overall_success = True
            
            # 1. åŒæ­¥äº¤æ˜“æ‰€ä¿¡æ¯
            if include_exchanges:
                logger.info("å¼€å§‹åŒæ­¥äº¤æ˜“æ‰€ä¿¡æ¯...")
                results['exchanges'] = self.sync_exchanges_info()
                if not results['exchanges']['success']:
                    overall_success = False
            
            # 2. åŒæ­¥è‚¡ç¥¨æ¸…å•
            if include_stock_lists:
                logger.info("å¼€å§‹åŒæ­¥è‚¡ç¥¨æ¸…å•...")
                results['stock_lists'] = self.sync_stock_lists()
                if not results['stock_lists']['success']:
                    overall_success = False
            
            # 3. åŒæ­¥è‚¡ç¥¨è¡Œæƒ…ï¼ˆå¯é€‰ï¼Œå› ä¸ºè€—æ—¶è¾ƒé•¿ï¼‰
            if include_stock_prices:
                logger.info("å¼€å§‹åŒæ­¥è‚¡ç¥¨è¡Œæƒ…æ•°æ®...")
                results['stock_prices'] = self.sync_stock_prices(
                    max_stocks=max_stocks,
                    start_year=start_year
                )
                if not results['stock_prices']['success']:
                    overall_success = False
            
            return {
                'success': overall_success,
                'action': 'completed',
                'message': 'å®Œæ•´åŒæ­¥ä»»åŠ¡å®Œæˆ',
                'included_tasks': {
                    'exchanges': include_exchanges,
                    'stock_lists': include_stock_lists,
                    'stock_prices': include_stock_prices
                },
                'results': results,
                'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            logger.error(f"å®Œæ•´åŒæ­¥å¤±è´¥: {e}")
            return {
                'success': False,
                'action': 'failed',
                'error': str(e),
                'message': 'å®Œæ•´åŒæ­¥å¤±è´¥'
            }
    
    def get_sync_status(self) -> Dict[str, Any]:
        """
        è·å–åŒæ­¥çŠ¶æ€ä¿¡æ¯
        
        Returns:
            Dict: çŠ¶æ€ä¿¡æ¯
        """
        try:
            status = {
                'exchanges': self._get_exchanges_status(),
                'stock_lists': self._get_stock_lists_status(),
                'database': self._get_database_status(),
                'last_check': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return status
            
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
            return {
                'error': str(e),
                'last_check': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def _get_all_stock_symbols(self, limit: int = 100) -> List[str]:
        """ä»æœ¬åœ°JSONæ–‡ä»¶è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç """
        try:
            from app.services.stock_info_service import StockInfoService
            service = StockInfoService()
            
            result = service.query_from_local_files(limit=limit)
            
            if result['success']:
                symbols = []
                for stock in result['data']:
                    ticker = stock.get('ticker', '')
                    exchange_code = stock.get('exchange_code', '')
                    
                    # è½¬æ¢ä¸ºé¡¹ç›®å†…éƒ¨æ ¼å¼
                    if exchange_code == 'XSHG' and ticker:
                        symbols.append(f"SH.{ticker}")
                    elif exchange_code == 'XSHE' and ticker:
                        symbols.append(f"SZ.{ticker}")
                    elif exchange_code == 'BJSE' and ticker:
                        symbols.append(f"BJ.{ticker}")
                
                return symbols
            
            return []
            
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def _get_exchanges_status(self) -> Dict[str, Any]:
        """è·å–äº¤æ˜“æ‰€ä¿¡æ¯çŠ¶æ€"""
        try:
            file_path = 'exchange_code.json'
            if os.path.exists(file_path):
                stat = os.stat(file_path)
                return {
                    'file_exists': True,
                    'file_path': file_path,
                    'file_size': stat.st_size,
                    'last_modified': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                    'age_hours': round((time.time() - stat.st_mtime) / 3600, 2)
                }
            else:
                return {
                    'file_exists': False,
                    'file_path': file_path,
                    'message': 'äº¤æ˜“æ‰€ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨'
                }
        except Exception as e:
            return {'error': str(e)}
    
    def _get_stock_lists_status(self) -> Dict[str, Any]:
        """è·å–è‚¡ç¥¨æ¸…å•çŠ¶æ€"""
        try:
            stock_lists_dir = 'constants/stock_lists'
            files = ['xshg_stocks.json', 'xshe_stocks.json', 'bjse_stocks.json']
            
            status = {}
            total_stocks = 0
            
            for filename in files:
                file_path = os.path.join(stock_lists_dir, filename)
                if os.path.exists(file_path):
                    stat = os.stat(file_path)
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        stock_count = len(data) if isinstance(data, list) else 0
                        total_stocks += stock_count
                    
                    status[filename] = {
                        'exists': True,
                        'stock_count': stock_count,
                        'file_size': stat.st_size,
                        'last_modified': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                    }
                else:
                    status[filename] = {
                        'exists': False,
                        'message': 'æ–‡ä»¶ä¸å­˜åœ¨'
                    }
            
            status['total_stocks'] = total_stocks
            return status
            
        except Exception as e:
            return {'error': str(e)}
    
    def _get_database_status(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“çŠ¶æ€"""
        try:
            from database.connection import db_manager
            
            # æµ‹è¯•è¿æ¥
            db_connected = db_manager.test_connection()
            
            status: Dict[str, Any] = {
                'connected': db_connected
            }
            
            if db_connected:
                # è·å–æ•°æ®åº“ä¸­çš„è‚¡ç¥¨æ•°æ®ç»Ÿè®¡
                try:
                    with db_manager.get_session() as session:
                        from models.stock_data import StockDailyData, StockInfo
                        
                        # è‚¡ç¥¨ä¿¡æ¯ç»Ÿè®¡
                        stock_info_count = session.query(StockInfo).count()
                        
                        # è¡Œæƒ…æ•°æ®ç»Ÿè®¡
                        stock_data_count = session.query(StockDailyData).count()
                        
                        # æœ€æ–°æ•°æ®æ—¥æœŸ
                        latest_data = session.query(StockDailyData.trade_date).order_by(
                            StockDailyData.trade_date.desc()
                        ).first()
                        
                        status.update({
                            'stock_info_count': stock_info_count,
                            'stock_data_count': stock_data_count,
                            'latest_data_date': latest_data[0].strftime('%Y-%m-%d') if latest_data else None
                        })
                        
                except Exception as e:
                    status['query_error'] = str(e)
            
            return status
            
        except Exception as e:
            return {
                'connected': False,
                'error': str(e)
            }